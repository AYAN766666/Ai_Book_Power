# Key Terms

This section provides definitions for important terms introduced in Chapter 14: Ethical and Societal Implications of Physical AI. Understanding these terms is crucial for engaging in responsible development and deployment of intelligent robots.

---

*   **AI Ethics**: A field of study exploring the moral, social, and legal issues arising from the development, deployment, and use of artificial intelligence.
*   **Beneficence**: The ethical principle that AI should be designed to do good and contribute positively to human well-being.
*   **Non-maleficence**: The ethical principle that AI should be designed to minimize harm and avoid causing physical, psychological, or societal damage.
*   **Accountability (AI Ethics)**: The principle that there must be clear lines of responsibility for the actions, decisions, and impacts of AI systems.
*   **Transparency (AI Ethics)**: The principle that the decision-making processes of AI systems should be understandable, predictable, and interpretable.
*   **Explainability (AI Ethics)**: The ability of an AI system to clarify its reasoning and provide understandable explanations for its outputs.
*   **Fairness (AI Ethics)**: The principle that AI systems should be designed to be unbiased, equitable, and not perpetuate or amplify societal discrimination.
*   **Privacy (AI Ethics)**: The right to be left alone and to have control over one's personal information, particularly concerning data collected by AI systems.
*   **Data Governance**: The overall management of data availability, usability, integrity, and security, especially as it relates to privacy and compliance.
*   **Human Control and Oversight**: The principle that humans should retain ultimate control over AI systems, with mechanisms for intervention and override.
*   **Autonomy (AI Ethics)**: The extent to which an AI system can operate and make decisions independently without direct human intervention, raising questions of responsibility.
*   **Automation Anxiety**: Public or worker concern about job displacement and the future of employment due to increasing automation and AI.
*   **Job Displacement**: The loss of jobs due to technological advancements, where machines perform tasks previously done by humans.
*   **Job Creation**: The emergence of new roles and industries as a result of technological advancements and automation.
*   **Job Augmentation**: The process where AI and robots assist human workers, taking over dangerous or tedious tasks and enhancing human capabilities, rather than replacing them.
*   **Collaborative Robots (Cobots - Ethical Context)**: Robots designed to work safely alongside humans, highlighting the ethical considerations of shared workspaces and human-robot collaboration.
*   **Skills Gap**: A mismatch between the skills possessed by the workforce and the skills required by emerging jobs, often exacerbated by rapid technological change.
*   **Universal Basic Income (UBI)**: A social safety net proposal where all citizens regularly receive a fixed income, potentially as a response to widespread job displacement from automation.
*   **Pervasive Sensing**: The widespread and continuous collection of data about an environment and its inhabitants through numerous sensors, raising significant privacy concerns.
*   **Surveillance (AI Context)**: The systematic monitoring of behavior and activities, often enabled by AI-powered cameras, microphones, and other sensors.
*   **Panopticon Effect**: The psychological impact of knowing one might be constantly observed, which can alter behavior even if actual surveillance is not occurring.
*   **Cybersecurity (Robotics)**: The protection of robotic systems and the data they handle from cyberattacks, unauthorized access, and malicious use.
*   **Privacy by Design**: An approach to developing systems and technologies with privacy protections built into them from the outset.
*   **Data Minimization**: The principle of collecting only the data strictly necessary for a system's specified purpose.
*   **Contextual Privacy**: The idea that what is considered private varies depending on the social situation, setting, or relationship.
*   **Trust Miscalibration (AI Ethics)**: Situations where human trust levels in an AI system do not accurately reflect the system's actual capabilities and limitations (e.g., over-trust or under-trust).
*   **Appropriate Trust (AI Ethics)**: The ideal state where human trust in an AI system is aligned with its actual capabilities and limitations.