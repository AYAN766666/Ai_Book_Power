# Key Terms

This section provides definitions for important terms introduced in Chapter 01: Introduction to Physical AI. Understanding these terms is crucial for grasping the foundational concepts of Physical AI and Humanoid Robotics.

---

*   **Physical Artificial Intelligence (Physical AI)**: Intelligent systems that interact with the real world through physical bodies, enabling perception, action, and learning within dynamic physical environments.
*   **Embodiment**: The concept that an agent's intelligence is deeply intertwined with its physical form, sensory-motor capabilities, and capacity for action within a physical world. The body shapes perception, reasoning, and interaction.
*   **Perception-Action Loop**: A continuous cycle in which an intelligent agent gathers information about its environment through sensors (perception), processes this information to make decisions, and then executes actions through its actuators.
*   **Proprioceptive Sensors**: Sensors that measure the internal state of a robot, such as joint angles, motor speeds, and forces applied to its body. Examples include encoders, IMUs, and force/torque sensors.
*   **Exteroceptive Sensors**: Sensors that gather information about the robot's external environment. Examples include cameras, Lidar, Radar, ultrasonic sensors, and tactile sensors.
*   **Inertial Measurement Unit (IMU)**: A device that typically combines accelerometers and gyroscopes (and sometimes magnetometers) to measure linear acceleration, angular velocity, and orientation (roll, pitch, yaw).
*   **Lidar (Light Detection and Ranging)**: A range sensor that uses pulsed lasers to measure distances and create highly accurate 2D or 3D maps of the environment.
*   **Radar (Radio Detection and Ranging)**: A range sensor that uses radio waves to detect objects and measure their range, velocity, and angle, often performing well in adverse weather conditions.
*   **Ultrasonic Sensor (Sonar)**: A range sensor that emits sound waves and measures the time for the echo to return to estimate distance, commonly used for short-range detection.
*   **Tactile Sensor**: A contact sensor that detects the presence or pressure of physical contact, often used in grippers or for collision detection.
*   **Sensor Fusion**: The process of combining data from multiple sensors to obtain a more complete, accurate, and reliable understanding of the environment and the robot's state.
*   **Center of Mass (CoM)**: The average position of all the mass in the robot. Its projection onto the ground is critical for maintaining balance.
*   **Zero Moment Point (ZMP)**: A theoretical point on the ground where the sum of all moments due to gravity and inertial forces is zero. For stable dynamic motion (e.g., walking), the ZMP must remain within the support polygon.
*   **Support Polygon**: The area on the ground defined by the points of contact between the robot's feet and the ground. The CoM projection or ZMP must stay within this polygon for stability.
*   **Reinforcement Learning**: A type of machine learning where an agent learns optimal behaviors through trial and error, receiving rewards for desired actions and penalties for undesirable ones.
*   **Humanoid Robotics**: The field of robotics focused on creating robots designed to mimic human form and capabilities, often built to operate in environments designed for humans.
*   **Soft Robotics**: A subfield of robotics that focuses on constructing robots from highly compliant materials, allowing for safer human-robot interaction and manipulation of delicate objects.
*   **Situatedness**: The concept that an intelligent system's actions and perceptions are context-dependent and intrinsically linked to its specific environment.
*   **Active Perception**: A process where an intelligent system actively moves or manipulates its sensors or environment to gather more information, rather than passively receiving data.